{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"../../src\")\n\nimport numpy as np\nimport pandas as pd\nfrom datetime import timedelta\nimport math\nimport lightgbm\n\n# from utils import ndcg_calculator\n# from LGBM_Rank import LGBMRank\n# from dataload import dataload, day_week_feature_engineering, train_label_split\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-11-28T05:31:34.473872Z","iopub.execute_input":"2022-11-28T05:31:34.474292Z","iopub.status.idle":"2022-11-28T05:31:35.377504Z","shell.execute_reply.started":"2022-11-28T05:31:34.474207Z","shell.execute_reply":"2022-11-28T05:31:35.376116Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"def _ndcg_calculator(gt, rec, idcg):\n    dcg = 0.0\n    for i, r in enumerate(rec):\n        if r in gt:\n            dcg += 1.0 / np.log(i + 2)\n    return dcg / idcg\n\ndef ndcg_calculator(answer, submission, n):\n    idcg = sum((1.0 / np.log(i + 1) for i in range(1, n + 1)))\n\n    assert (answer.profile_id != submission.profile_id).sum() == 0\n\n    ndcg_list = []\n    for (_, row_answer), (_, row_submit) in zip(answer.iterrows(), submission.iterrows()):\n        ndcg_list.append(_ndcg_calculator(row_answer.album_id, row_submit.album_id, idcg))\n\n    ndcg_score = sum(ndcg_list) / len(answer)\n    return ndcg_score\n\nclass LGBMRank():\n    def __init__(self, \n                train_df:pd.DataFrame(), \n                model_params:dict={'n_estimators':5},\n                path:str='../../data/',\n                mode:str='week',\n                n=25):\n\n        self.train_df = train_df\n        self.path = path\n        self.model_params = model_params\n        self.sample_sumbission_week = pd.read_parquet(path + 'sample_sumbission_week.parquet')\n        self.sample_sumbission_month = pd.read_parquet(path + 'sample_sumbission_month.parquet')\n        self.test_answer_week = pd.read_parquet(path + 'test_answer_week.parquet')\n        self.test_answer_month = pd.read_parquet(path + 'test_answer_month.parquet')\n        self.mode = mode\n\n        self.n = n\n        self.X_train, self.y_train, self.train_group = self.lgbm_preprocess(self.train_df)\n\n\n\n\n    def lgbm_preprocess(self, train_df:pd.DataFrame()):\n        X_train = train_df.drop(columns=['rating'])\n        y_train = train_df['rating']\n        \n        train_group = train_df.groupby('profile_id')['profile_id'].count().to_numpy()\n\n        self.item_idx = X_train[\"album_id\"].copy()\n        self.user_idx = X_train[\"profile_id\"].copy()\n        del X_train[\"album_id\"], X_train[\"profile_id\"]\n\n        return X_train, y_train, train_group\n\n\n\n\n    def train(self):\n\n        model_params = self.model_params\n\n        model = lightgbm.LGBMRanker(\n            objective=\"lambdarank\",\n            metric=\"ndcg\",\n            boosting_type=\"dart\",\n            num_leaves= 20,\n            learning_rate=0.005,\n            n_estimators= model_params['n_estimators'],\n            importance_type='gain',\n            verbose= -1,\n            random_state= 42\n        )\n        \n        model.fit(\n        X=self.X_train,\n        y=self.y_train,\n        group=self.train_group,\n        )\n        \n        feature_importances_df = pd.DataFrame(dict(zip(self.X_train.columns, model.feature_importances_)), \\\n                                            index=['feature_importances']).T\n        \n\n        return model, feature_importances_df\n\n\n\n\n    def valid_evaluation(self)->pd.DataFrame():\n        \n        X_train = self.X_train\n        n = self.n\n        \n        model, feature_importances_df = self.train()\n        print(feature_importances_df)\n\n        pred = model.predict(X_train)\n        X_train['pred'] = pred\n\n        item_idx = self.item_idx \n        user_idx = self.user_idx\n        X_train[\"album_id\"] = item_idx\n        X_train[\"profile_id\"] = user_idx\n\n        if self.mode == 'week':\n            sample_sumbission = self.sample_sumbission_week\n            test_answer = self.test_answer_week\n            print('week performance')\n        else:\n            sample_sumbission = self.sample_sumbission_month\n            test_answer = self.test_answer_month\n            print('month performance')\n        \n        # each user pred 25 items\n        lgbm_sub_df = X_train.sort_values(by='pred', ascending=False).groupby('profile_id').head(25)\n        lgbm_user_items_dict = lgbm_sub_df.groupby('profile_id')['album_id'].unique().to_dict()\n        sample_sumbission['album_id'] = sample_sumbission['profile_id'].apply(lambda x: lgbm_user_items_dict.get(x, []))\n\n        print('lgbm ndcg:', ndcg_calculator(sample_sumbission, test_answer, n))\n        \n        return X_train, sample_sumbission\n    \ndef dataload(path:str='../../data/'):\n\n    test_answer_week = pd.read_parquet(path + \"test_answer_week.parquet\")\n    test_answer_month = pd.read_parquet(path + \"test_answer_month.parquet\")\n\n    df_train_week = pd.read_parquet(path + \"train_week.parquet\")\n    df_train_month = pd.read_parquet(path + \"train_month.parquet\")\n\n    sample_sumbission_week = pd.read_parquet(path + \"sample_sumbission_week.parquet\")\n    sample_sumbission_month = pd.read_parquet(path + \"sample_sumbission_month.parquet\")\n\n    df_train_week.sort_values(by='log_dt', inplace=True)\n    df_train_month.sort_values(by='log_dt', inplace=True)\n    \n    return test_answer_week, test_answer_month, df_train_week, df_train_month, sample_sumbission_week, sample_sumbission_month\n\n\n\n\n# week & day feature engineering\ndef day_feature(df_train:pd.DataFrame())->pd.Series():\n    dates = df_train.log_date\n    unique_dates = df_train.log_date.unique()\n    unique_dates = np.sort(unique_dates)\n    number_range = np.arange(len(unique_dates))\n    date_number_dict = dict(zip(unique_dates, number_range))\n\n    all_day_numbers = dates.map(date_number_dict)\n    all_day_numbers = all_day_numbers.astype(\"int16\")\n    print('log date min:', dates.min(), 'log date max:', dates.max())\n    print('min day:', all_day_numbers.min(), 'max day:', all_day_numbers.max())\n\n    return all_day_numbers\n\ndef week_feature(df_train:pd.DataFrame())->pd.Series:\n    pd_dates = df_train.log_date\n    unique_dates = pd.Series(df_train.log_date.unique())\n    numbered_days = unique_dates - unique_dates.min() + timedelta(1)\n    numbered_days = numbered_days.dt.days\n    extra_days = numbered_days.max() % 7\n    numbered_days -= extra_days\n    day_weeks = (numbered_days / 7).apply(lambda x: math.ceil(x))\n    day_weeks_map = pd.DataFrame({\"day_weeks\": day_weeks, \"unique_dates\": unique_dates})\\\n                                                        .set_index(\"unique_dates\")[\"day_weeks\"]\n    all_day_weeks = pd_dates.map(day_weeks_map)\n    all_day_weeks = all_day_weeks.astype(\"int8\")\n    print('min week:', all_day_weeks.min(), 'max week:', all_day_weeks.max())\n\n    return all_day_weeks\n\ndef day_week_feature_engineering(df_train:pd.DataFrame())->pd.DataFrame():\n    all_day_numbers = day_feature(df_train)\n    all_day_weeks = week_feature(df_train)\n    \n    df_train['day'] = all_day_numbers\n    df_train['week'] = all_day_weeks\n\n    return df_train\n\n\n# train, label split\ndef train_label_split(df_train:pd.DataFrame())->pd.DataFrame():\n    last_week = df_train['week'].max()\n    print('split last week:', last_week)\n\n    label_df = df_train.query(f'week=={last_week}')[['profile_id','album_id']]\n    label_df.drop_duplicates(subset=['profile_id','album_id'],inplace=True)\n    label_df['rating'] = 1\n\n    df_train = df_train.query(f\"week <= {last_week}\")\n    \n    return df_train, label_df","metadata":{"execution":{"iopub.status.busy":"2022-11-28T05:31:35.379367Z","iopub.execute_input":"2022-11-28T05:31:35.379674Z","iopub.status.idle":"2022-11-28T05:31:35.415676Z","shell.execute_reply.started":"2022-11-28T05:31:35.379647Z","shell.execute_reply":"2022-11-28T05:31:35.413729Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:143: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# dataload","metadata":{}},{"cell_type":"code","source":"path='/kaggle/input/lg-train-test/'\n\ntest_answer_week, test_answer_month, \\\ndf_train_week, df_train_month, \\\nsample_sumbission_week, sample_sumbission_month = dataload(path)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T05:31:35.973511Z","iopub.execute_input":"2022-11-28T05:31:35.973896Z","iopub.status.idle":"2022-11-28T05:31:36.567654Z","shell.execute_reply.started":"2022-11-28T05:31:35.973868Z","shell.execute_reply":"2022-11-28T05:31:36.566201Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# # 전체 데이터 이용시\n# df_history = pd.read_csv(\"/kaggle/input/lgground/history_data.csv\")\n\n# ## 날짜 전처리\n# df_history = df_history.assign(log_dt = pd.to_datetime(df_history.log_time//100, format=\"%Y%m%d%H%M\"))\n# df_history = df_history.assign(log_date = df_history.log_dt.dt.floor(\"D\"))\n# df_history = df_history.drop(\"log_time\", axis=1)\n\n# df_train_week = df_history.copy()\n\n# # month 이용\n# # df_train_week = df_train_month.copy()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T05:31:36.674312Z","iopub.execute_input":"2022-11-28T05:31:36.675581Z","iopub.status.idle":"2022-11-28T05:31:36.679329Z","shell.execute_reply.started":"2022-11-28T05:31:36.675522Z","shell.execute_reply":"2022-11-28T05:31:36.678378Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering","metadata":{}},{"cell_type":"markdown","source":"## History\n+Add [album_viewcount] : History 내 Album id 에 대한 Frequency Encoding   \nShort trailer - one hot   \nContinuous play - one hot   ","metadata":{}},{"cell_type":"code","source":"df_train_week.drop_duplicates()\n# 945518 > 812471\ndf_train_week.info()\n\n# History의 경우, 일단은 바로바로 모델성능을 실험할 week 데이터셋에 진행 \n# categorical은 한번에 처리 가능하게 함수화 (full에도 바로 반영 가능하도록)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T06:53:18.045593Z","iopub.execute_input":"2022-11-28T06:53:18.046005Z","iopub.status.idle":"2022-11-28T06:53:18.408588Z","shell.execute_reply.started":"2022-11-28T06:53:18.045972Z","shell.execute_reply":"2022-11-28T06:53:18.407545Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 945518 entries, 899160 to 127159\nData columns (total 11 columns):\n #   Column                       Non-Null Count   Dtype         \n---  ------                       --------------   -----         \n 0   profile_id                   945518 non-null  int64         \n 1   ss_id                        945518 non-null  int64         \n 2   act_target_dtl               945518 non-null  object        \n 3   album_id                     945518 non-null  int64         \n 4   payment                      68144 non-null   float64       \n 5   continuous_play              945518 non-null  category      \n 6   short_trailer                945518 non-null  category      \n 7   log_dt                       945518 non-null  datetime64[ns]\n 8   log_date                     945518 non-null  datetime64[ns]\n 9   album_viewcount_freq_encode  945518 non-null  float64       \n 10  album_viewcount_freq         945518 non-null  float64       \ndtypes: category(2), datetime64[ns](2), float64(3), int64(3), object(1)\nmemory usage: 73.9+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"####### History \n\ndef history_feature_engineering(df):\n    \n    ####### Short trailer & Continuous play - categorical\n    cat_features = ['short_trailer','continuous_play']\n    for i in enumerate (cat_features) :\n        col = i[1]\n        df[col] = df[col].astype('category')\n        \n    ####### album_viewcount - Frequency    \n    album_viewcount_df = df.groupby(\"album_id\").size()/len(df)\n    df.loc[:, \"album_viewcount_freq\"] = df[\"album_id\"].map(album_viewcount_df)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-11-28T05:49:46.762466Z","iopub.execute_input":"2022-11-28T05:49:46.762941Z","iopub.status.idle":"2022-11-28T05:49:46.770479Z","shell.execute_reply.started":"2022-11-28T05:49:46.762903Z","shell.execute_reply":"2022-11-28T05:49:46.769424Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"history_feature_engineering(df_train_week)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T05:49:46.889140Z","iopub.execute_input":"2022-11-28T05:49:46.889817Z","iopub.status.idle":"2022-11-28T05:49:47.017142Z","shell.execute_reply.started":"2022-11-28T05:49:46.889744Z","shell.execute_reply":"2022-11-28T05:49:47.015888Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"        profile_id           ss_id act_target_dtl  album_id  payment  \\\n899160       25844  20220301000456        MKID003     18024      NaN   \n899162       25844  20220301000456        MKID003      1881      NaN   \n899161       25844  20220301000456        MKID003      1881      NaN   \n899163       25844  20220301000456        MKID003      4608      NaN   \n899164       25844  20220301000456        MKID003      4608      NaN   \n...            ...             ...            ...       ...      ...   \n58990         1847  20220423220455        MKID003       472      NaN   \n724845       19290  20220423235128        MKID003      2285      NaN   \n724844       19290  20220423235128        MKID003      2285      NaN   \n677911       17755  20220423235282        MKID003       315      NaN   \n127159        2794  20220423230692        MKID003       347      NaN   \n\n       continuous_play short_trailer              log_dt   log_date  \\\n899160               N             N 2022-03-01 00:04:00 2022-03-01   \n899162               N             N 2022-03-01 00:05:00 2022-03-01   \n899161               N             N 2022-03-01 00:05:00 2022-03-01   \n899163               N             N 2022-03-01 00:06:00 2022-03-01   \n899164               N             N 2022-03-01 00:06:00 2022-03-01   \n...                ...           ...                 ...        ...   \n58990                Y             N 2022-04-23 23:59:00 2022-04-23   \n724845               Y             N 2022-04-23 23:59:00 2022-04-23   \n724844               Y             N 2022-04-23 23:59:00 2022-04-23   \n677911               N             N 2022-04-23 23:59:00 2022-04-23   \n127159               Y             N 2022-04-23 23:59:00 2022-04-23   \n\n        album_viewcount_freq_encode  album_viewcount_freq  \n899160                     0.000010              0.000010  \n899162                     0.001322              0.001322  \n899161                     0.001322              0.001322  \n899163                     0.000635              0.000635  \n899164                     0.000635              0.000635  \n...                             ...                   ...  \n58990                      0.000315              0.000315  \n724845                     0.000579              0.000579  \n724844                     0.000579              0.000579  \n677911                     0.000151              0.000151  \n127159                     0.003651              0.003651  \n\n[945518 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>profile_id</th>\n      <th>ss_id</th>\n      <th>act_target_dtl</th>\n      <th>album_id</th>\n      <th>payment</th>\n      <th>continuous_play</th>\n      <th>short_trailer</th>\n      <th>log_dt</th>\n      <th>log_date</th>\n      <th>album_viewcount_freq_encode</th>\n      <th>album_viewcount_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>899160</th>\n      <td>25844</td>\n      <td>20220301000456</td>\n      <td>MKID003</td>\n      <td>18024</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>N</td>\n      <td>2022-03-01 00:04:00</td>\n      <td>2022-03-01</td>\n      <td>0.000010</td>\n      <td>0.000010</td>\n    </tr>\n    <tr>\n      <th>899162</th>\n      <td>25844</td>\n      <td>20220301000456</td>\n      <td>MKID003</td>\n      <td>1881</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>N</td>\n      <td>2022-03-01 00:05:00</td>\n      <td>2022-03-01</td>\n      <td>0.001322</td>\n      <td>0.001322</td>\n    </tr>\n    <tr>\n      <th>899161</th>\n      <td>25844</td>\n      <td>20220301000456</td>\n      <td>MKID003</td>\n      <td>1881</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>N</td>\n      <td>2022-03-01 00:05:00</td>\n      <td>2022-03-01</td>\n      <td>0.001322</td>\n      <td>0.001322</td>\n    </tr>\n    <tr>\n      <th>899163</th>\n      <td>25844</td>\n      <td>20220301000456</td>\n      <td>MKID003</td>\n      <td>4608</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>N</td>\n      <td>2022-03-01 00:06:00</td>\n      <td>2022-03-01</td>\n      <td>0.000635</td>\n      <td>0.000635</td>\n    </tr>\n    <tr>\n      <th>899164</th>\n      <td>25844</td>\n      <td>20220301000456</td>\n      <td>MKID003</td>\n      <td>4608</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>N</td>\n      <td>2022-03-01 00:06:00</td>\n      <td>2022-03-01</td>\n      <td>0.000635</td>\n      <td>0.000635</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58990</th>\n      <td>1847</td>\n      <td>20220423220455</td>\n      <td>MKID003</td>\n      <td>472</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000315</td>\n      <td>0.000315</td>\n    </tr>\n    <tr>\n      <th>724845</th>\n      <td>19290</td>\n      <td>20220423235128</td>\n      <td>MKID003</td>\n      <td>2285</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000579</td>\n      <td>0.000579</td>\n    </tr>\n    <tr>\n      <th>724844</th>\n      <td>19290</td>\n      <td>20220423235128</td>\n      <td>MKID003</td>\n      <td>2285</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000579</td>\n      <td>0.000579</td>\n    </tr>\n    <tr>\n      <th>677911</th>\n      <td>17755</td>\n      <td>20220423235282</td>\n      <td>MKID003</td>\n      <td>315</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000151</td>\n      <td>0.000151</td>\n    </tr>\n    <tr>\n      <th>127159</th>\n      <td>2794</td>\n      <td>20220423230692</td>\n      <td>MKID003</td>\n      <td>347</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.003651</td>\n      <td>0.003651</td>\n    </tr>\n  </tbody>\n</table>\n<p>945518 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## float64 는 최대한 피해야 하긴 하는데.... memory reduce 단계에서 다시 고려\n# 아니다 memory reduce도 데이터셋마다 고려해야 할지도. (history제외한 나머지는 함께 고려 가능(모아 붙이는 형태니까)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Watch\nContinuous play - categorical","metadata":{}},{"cell_type":"code","source":"watch = pd.read_csv(\"/kaggle/input/lgground/watch_e_data.csv\")\nwatch.info()\n# We only use [total_time] and [continuous_play] columns","metadata":{"execution":{"iopub.status.busy":"2022-11-28T05:37:25.094066Z","iopub.execute_input":"2022-11-28T05:37:25.095618Z","iopub.status.idle":"2022-11-28T05:37:25.608758Z","shell.execute_reply.started":"2022-11-28T05:37:25.095558Z","shell.execute_reply":"2022-11-28T05:37:25.607243Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 892794 entries, 0 to 892793\nData columns (total 8 columns):\n #   Column           Non-Null Count   Dtype \n---  ------           --------------   ----- \n 0   profile_id       892794 non-null  int64 \n 1   ss_id            892794 non-null  int64 \n 2   log_time         892794 non-null  int64 \n 3   act_target_dtl   892794 non-null  object\n 4   album_id         892794 non-null  int64 \n 5   watch_time       892794 non-null  int64 \n 6   total_time       892794 non-null  int64 \n 7   continuous_play  892794 non-null  int64 \ndtypes: int64(7), object(1)\nmemory usage: 54.5+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"def watch_feature_engineering(watch):\n    watch['continuous_play'] = watch['continuous_play'].astype('category')\n    watch_feature = watch[['profile_id','album_id','watch_time','total_time']]\n    return watch_feature","metadata":{"execution":{"iopub.status.busy":"2022-11-28T05:53:03.474790Z","iopub.execute_input":"2022-11-28T05:53:03.475166Z","iopub.status.idle":"2022-11-28T05:53:03.481084Z","shell.execute_reply.started":"2022-11-28T05:53:03.475136Z","shell.execute_reply":"2022-11-28T05:53:03.479725Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"watch_feature_engineering(watch)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T05:53:03.603278Z","iopub.execute_input":"2022-11-28T05:53:03.603933Z","iopub.status.idle":"2022-11-28T05:53:03.617591Z","shell.execute_reply.started":"2022-11-28T05:53:03.603898Z","shell.execute_reply":"2022-11-28T05:53:03.616545Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# watch에서 사용할 column만 따로 저장 (그런데 이어붙이러면 key가 필요한데.)\n# [total_time] 은 무조건 album id 기준으로 merge 가능\n# [continuous_play] 는 album+column id 기준으로 붙여볼 수 있을지도. (결측 예상)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## buy & Search\n\nbuy :::  +Add [Paid] column : 아이템별 유료항목 여부 - one hot [유료:1 / 무료 :0]    \nSearch ::: +Add [Searched] column : 아이템별 검색시청 여부 - One hot [검색됨:1 / 안됨:0]","metadata":{}},{"cell_type":"code","source":"buy = pd.read_csv(\"/kaggle/input/lgground/buy_data.csv\")\nsearch = pd.read_csv(\"/kaggle/input/lgground/search_data.csv\")\n# We only use [viewing log] from these datasets","metadata":{"execution":{"iopub.status.busy":"2022-11-28T06:07:47.382840Z","iopub.execute_input":"2022-11-28T06:07:47.383212Z","iopub.status.idle":"2022-11-28T06:07:47.455102Z","shell.execute_reply.started":"2022-11-28T06:07:47.383179Z","shell.execute_reply":"2022-11-28T06:07:47.453842Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def paid_feature(df,buy):\n    buy_album = buy['profile_id'].unique().tolist()   # nunique 17개 뿐\n\n    history_pay = df[['album_id','payment']].copy()  # history의 pay nunique 7168\n    history_buy_album = history_pay.dropna().drop_duplicates().album_id.unique().tolist()\n\n    paid_album = pd.DataFrame(list(set(buy_album + history_buy_album))).rename(columns={0:'album_id'})  # nunique 7181\n\n    paid_df = pd.concat([paid_album.assign(label=True),df.assign(label=False)]).rename(columns={'label':'Paid'})\n    paid_df['Paid'] = paid_df['Paid'].astype('category')\n    return paid_df","metadata":{"execution":{"iopub.status.busy":"2022-11-28T06:52:05.826509Z","iopub.execute_input":"2022-11-28T06:52:05.826919Z","iopub.status.idle":"2022-11-28T06:52:05.836447Z","shell.execute_reply.started":"2022-11-28T06:52:05.826885Z","shell.execute_reply":"2022-11-28T06:52:05.834694Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"##### searched \n# train data를 넣으면 알아서 concat하고 라벨링도 되게끔. 여기에 카테고리화까지. \n# info로 정상동작 확인 완료\n# 1977개 \n\ndef searched_feature(df,search):\n    search_album = pd.DataFrame(search['album_id'].unique().tolist()).rename(columns={0:'album_id'})\n    searched_df = pd.concat([search_album.assign(label=True),df.assign(label=False)]).rename(columns={'label':'Searched'})\n    searched_df['Searched'] = searched_df['Searched'].astype('category')\n    return searched_df","metadata":{"execution":{"iopub.status.busy":"2022-11-28T06:48:44.045544Z","iopub.execute_input":"2022-11-28T06:48:44.045933Z","iopub.status.idle":"2022-11-28T06:48:44.052195Z","shell.execute_reply.started":"2022-11-28T06:48:44.045901Z","shell.execute_reply":"2022-11-28T06:48:44.051278Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"paid_feature(df_train_week,buy)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T06:52:06.612792Z","iopub.execute_input":"2022-11-28T06:52:06.613446Z","iopub.status.idle":"2022-11-28T06:52:06.738680Z","shell.execute_reply.started":"2022-11-28T06:52:06.613415Z","shell.execute_reply":"2022-11-28T06:52:06.737119Z"},"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"        album_id   Paid  profile_id         ss_id act_target_dtl  payment  \\\n0              6   True         NaN           NaN            NaN      NaN   \n1             33   True         NaN           NaN            NaN      NaN   \n2             59   True         NaN           NaN            NaN      NaN   \n3             61   True         NaN           NaN            NaN      NaN   \n4             74   True         NaN           NaN            NaN      NaN   \n...          ...    ...         ...           ...            ...      ...   \n58990        472  False      1847.0  2.022042e+13        MKID003      NaN   \n724845      2285  False     19290.0  2.022042e+13        MKID003      NaN   \n724844      2285  False     19290.0  2.022042e+13        MKID003      NaN   \n677911       315  False     17755.0  2.022042e+13        MKID003      NaN   \n127159       347  False      2794.0  2.022042e+13        MKID003      NaN   \n\n       continuous_play short_trailer              log_dt   log_date  \\\n0                  NaN           NaN                 NaT        NaT   \n1                  NaN           NaN                 NaT        NaT   \n2                  NaN           NaN                 NaT        NaT   \n3                  NaN           NaN                 NaT        NaT   \n4                  NaN           NaN                 NaT        NaT   \n...                ...           ...                 ...        ...   \n58990                Y             N 2022-04-23 23:59:00 2022-04-23   \n724845               Y             N 2022-04-23 23:59:00 2022-04-23   \n724844               Y             N 2022-04-23 23:59:00 2022-04-23   \n677911               N             N 2022-04-23 23:59:00 2022-04-23   \n127159               Y             N 2022-04-23 23:59:00 2022-04-23   \n\n        album_viewcount_freq_encode  album_viewcount_freq  \n0                               NaN                   NaN  \n1                               NaN                   NaN  \n2                               NaN                   NaN  \n3                               NaN                   NaN  \n4                               NaN                   NaN  \n...                             ...                   ...  \n58990                      0.000315              0.000315  \n724845                     0.000579              0.000579  \n724844                     0.000579              0.000579  \n677911                     0.000151              0.000151  \n127159                     0.003651              0.003651  \n\n[952699 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>album_id</th>\n      <th>Paid</th>\n      <th>profile_id</th>\n      <th>ss_id</th>\n      <th>act_target_dtl</th>\n      <th>payment</th>\n      <th>continuous_play</th>\n      <th>short_trailer</th>\n      <th>log_dt</th>\n      <th>log_date</th>\n      <th>album_viewcount_freq_encode</th>\n      <th>album_viewcount_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>59</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>74</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58990</th>\n      <td>472</td>\n      <td>False</td>\n      <td>1847.0</td>\n      <td>2.022042e+13</td>\n      <td>MKID003</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000315</td>\n      <td>0.000315</td>\n    </tr>\n    <tr>\n      <th>724845</th>\n      <td>2285</td>\n      <td>False</td>\n      <td>19290.0</td>\n      <td>2.022042e+13</td>\n      <td>MKID003</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000579</td>\n      <td>0.000579</td>\n    </tr>\n    <tr>\n      <th>724844</th>\n      <td>2285</td>\n      <td>False</td>\n      <td>19290.0</td>\n      <td>2.022042e+13</td>\n      <td>MKID003</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000579</td>\n      <td>0.000579</td>\n    </tr>\n    <tr>\n      <th>677911</th>\n      <td>315</td>\n      <td>False</td>\n      <td>17755.0</td>\n      <td>2.022042e+13</td>\n      <td>MKID003</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000151</td>\n      <td>0.000151</td>\n    </tr>\n    <tr>\n      <th>127159</th>\n      <td>347</td>\n      <td>False</td>\n      <td>2794.0</td>\n      <td>2.022042e+13</td>\n      <td>MKID003</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.003651</td>\n      <td>0.003651</td>\n    </tr>\n  </tbody>\n</table>\n<p>952699 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"searched_feature(df_train_week,search)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T06:48:45.148402Z","iopub.execute_input":"2022-11-28T06:48:45.149343Z","iopub.status.idle":"2022-11-28T06:48:45.258945Z","shell.execute_reply.started":"2022-11-28T06:48:45.149309Z","shell.execute_reply":"2022-11-28T06:48:45.257897Z"},"trusted":true},"execution_count":114,"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"        album_id Searched  profile_id         ss_id act_target_dtl  payment  \\\n0           2141     True         NaN           NaN            NaN      NaN   \n1            512     True         NaN           NaN            NaN      NaN   \n2           2142     True         NaN           NaN            NaN      NaN   \n3           2143     True         NaN           NaN            NaN      NaN   \n4           2150     True         NaN           NaN            NaN      NaN   \n...          ...      ...         ...           ...            ...      ...   \n58990        472    False      1847.0  2.022042e+13        MKID003      NaN   \n724845      2285    False     19290.0  2.022042e+13        MKID003      NaN   \n724844      2285    False     19290.0  2.022042e+13        MKID003      NaN   \n677911       315    False     17755.0  2.022042e+13        MKID003      NaN   \n127159       347    False      2794.0  2.022042e+13        MKID003      NaN   \n\n       continuous_play short_trailer              log_dt   log_date  \\\n0                  NaN           NaN                 NaT        NaT   \n1                  NaN           NaN                 NaT        NaT   \n2                  NaN           NaN                 NaT        NaT   \n3                  NaN           NaN                 NaT        NaT   \n4                  NaN           NaN                 NaT        NaT   \n...                ...           ...                 ...        ...   \n58990                Y             N 2022-04-23 23:59:00 2022-04-23   \n724845               Y             N 2022-04-23 23:59:00 2022-04-23   \n724844               Y             N 2022-04-23 23:59:00 2022-04-23   \n677911               N             N 2022-04-23 23:59:00 2022-04-23   \n127159               Y             N 2022-04-23 23:59:00 2022-04-23   \n\n        album_viewcount_freq_encode  album_viewcount_freq  \n0                               NaN                   NaN  \n1                               NaN                   NaN  \n2                               NaN                   NaN  \n3                               NaN                   NaN  \n4                               NaN                   NaN  \n...                             ...                   ...  \n58990                      0.000315              0.000315  \n724845                     0.000579              0.000579  \n724844                     0.000579              0.000579  \n677911                     0.000151              0.000151  \n127159                     0.003651              0.003651  \n\n[947495 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>album_id</th>\n      <th>Searched</th>\n      <th>profile_id</th>\n      <th>ss_id</th>\n      <th>act_target_dtl</th>\n      <th>payment</th>\n      <th>continuous_play</th>\n      <th>short_trailer</th>\n      <th>log_dt</th>\n      <th>log_date</th>\n      <th>album_viewcount_freq_encode</th>\n      <th>album_viewcount_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2141</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>512</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2142</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2143</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2150</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58990</th>\n      <td>472</td>\n      <td>False</td>\n      <td>1847.0</td>\n      <td>2.022042e+13</td>\n      <td>MKID003</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000315</td>\n      <td>0.000315</td>\n    </tr>\n    <tr>\n      <th>724845</th>\n      <td>2285</td>\n      <td>False</td>\n      <td>19290.0</td>\n      <td>2.022042e+13</td>\n      <td>MKID003</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000579</td>\n      <td>0.000579</td>\n    </tr>\n    <tr>\n      <th>724844</th>\n      <td>2285</td>\n      <td>False</td>\n      <td>19290.0</td>\n      <td>2.022042e+13</td>\n      <td>MKID003</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000579</td>\n      <td>0.000579</td>\n    </tr>\n    <tr>\n      <th>677911</th>\n      <td>315</td>\n      <td>False</td>\n      <td>17755.0</td>\n      <td>2.022042e+13</td>\n      <td>MKID003</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.000151</td>\n      <td>0.000151</td>\n    </tr>\n    <tr>\n      <th>127159</th>\n      <td>347</td>\n      <td>False</td>\n      <td>2794.0</td>\n      <td>2.022042e+13</td>\n      <td>MKID003</td>\n      <td>NaN</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>2022-04-23 23:59:00</td>\n      <td>2022-04-23</td>\n      <td>0.003651</td>\n      <td>0.003651</td>\n    </tr>\n  </tbody>\n</table>\n<p>947495 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## meta\n\nCast - one hot   \nGenre - (dummies) / <고민>   \nCountry - one (결측 - unknown)   \nRun time - numerical   \nTag - 고민    \n\nmeta_plus 사용 고민 ","metadata":{}},{"cell_type":"code","source":"meta = pd.read_csv(\"/kaggle/input/lgground/meta_data.csv\")\nmeta.info()\n\n# we use  / sub_title / genre_large / genre_mid / run_time / country\n\n############################### meta의 run_time과 watch의 total_time의 차이\n# 결측치가 많은 고려 대상\n# genre_small / cast 들","metadata":{"execution":{"iopub.status.busy":"2022-11-28T07:05:10.064389Z","iopub.execute_input":"2022-11-28T07:05:10.064854Z","iopub.status.idle":"2022-11-28T07:05:10.187873Z","shell.execute_reply.started":"2022-11-28T07:05:10.064817Z","shell.execute_reply":"2022-11-28T07:05:10.186443Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 42602 entries, 0 to 42601\nData columns (total 16 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   album_id     42602 non-null  int64  \n 1   title        42602 non-null  object \n 2   sub_title    42602 non-null  object \n 3   genre_large  42602 non-null  object \n 4   genre_mid    42602 non-null  object \n 5   genre_small  13419 non-null  object \n 6   country      33734 non-null  object \n 7   run_time     42602 non-null  int64  \n 8   onair_date   5344 non-null   float64\n 9   cast_1       27603 non-null  object \n 10  cast_2       22048 non-null  object \n 11  cast_3       16463 non-null  object \n 12  cast_4       12485 non-null  object \n 13  cast_5       6382 non-null   object \n 14  cast_6       2609 non-null   object \n 15  cast_7       762 non-null    object \ndtypes: float64(1), int64(2), object(13)\nmemory usage: 5.2+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"########## sub title은 카테고리로 넣을 만 하다!\n# meta.title.nunique()  #36185\n# meta.sub_title.nunique()  #2373","metadata":{"execution":{"iopub.status.busy":"2022-11-28T07:32:50.279831Z","iopub.execute_input":"2022-11-28T07:32:50.280172Z","iopub.status.idle":"2022-11-28T07:32:50.291982Z","shell.execute_reply.started":"2022-11-28T07:32:50.280140Z","shell.execute_reply":"2022-11-28T07:32:50.291027Z"},"trusted":true},"execution_count":156,"outputs":[{"execution_count":156,"output_type":"execute_result","data":{"text/plain":"2373"},"metadata":{}}]},{"cell_type":"code","source":"# meta['sub_title']  # 같은 앨범 id에 다른 sub_title \n\n########### 고민 더 해봐야 함 ","metadata":{"execution":{"iopub.status.busy":"2022-11-28T07:51:26.610762Z","iopub.execute_input":"2022-11-28T07:51:26.612348Z","iopub.status.idle":"2022-11-28T07:51:26.622737Z","shell.execute_reply.started":"2022-11-28T07:51:26.612294Z","shell.execute_reply":"2022-11-28T07:51:26.620963Z"},"trusted":true},"execution_count":163,"outputs":[{"execution_count":163,"output_type":"execute_result","data":{"text/plain":"0          꼬마버스 타요1\n1          꼬마버스 타요1\n2          꼬마버스 타요1\n3          꼬마버스 타요1\n4          꼬마버스 타요1\n            ...    \n42597    로티프렌즈 미술놀이\n42598    로티프렌즈 미술놀이\n42599          4-5세\n42600          아이맘콕\n42601    베이비 타요 동요2\nName: sub_title, Length: 42602, dtype: category\nCategories (2373, object): ['100분! 뽀요 인기 메들리', '100분! 뽀요 인기 메들리2', '10월 세계 여러나라', '11월 지구와 우주', ..., '히어로 써클', '힙합동요 쪼이송 공룡나라1', '힙합동요 쪼이송 동물퀴즈송 배우기1', '힙합동요 쪼이송 동물퀴즈송1']"},"metadata":{}}]},{"cell_type":"code","source":"# meta.country.unique()   ## 그래 이정도는 categorical로 넣을 만 하다!\n### 한국 / 미국 /  컨텐츠가 너무 개수 적은 것은 합쳐서 카테고리화","metadata":{"execution":{"iopub.status.busy":"2022-11-28T07:40:43.127080Z","iopub.execute_input":"2022-11-28T07:40:43.127499Z","iopub.status.idle":"2022-11-28T07:40:43.137398Z","shell.execute_reply.started":"2022-11-28T07:40:43.127464Z","shell.execute_reply":"2022-11-28T07:40:43.136313Z"},"trusted":true},"execution_count":158,"outputs":[{"execution_count":158,"output_type":"execute_result","data":{"text/plain":"array(['한국', '저지', nan, '미국', '영국', '일본', '중국', '프랑스', '오스트리아', '독일',\n       '이탈리아', '크로아티아', '스위스', '캐나다', '아르헨티나', '우크라이나', '핀란드', '이스라엘',\n       '벨기에', '벨라루스', '네덜란드'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"def meta_feature_engineering(meta):\n    \n    ####### sub_title & genre_large & genre_mid - categorical\n    cat_features = ['sub_title','genre_large','genre_mid','country']\n    for i in enumerate (cat_features) :\n        col = i[1]\n        meta[col] = meta[col].astype('category')\n    return meta","metadata":{"execution":{"iopub.status.busy":"2022-11-28T07:42:19.298030Z","iopub.execute_input":"2022-11-28T07:42:19.298426Z","iopub.status.idle":"2022-11-28T07:42:19.304693Z","shell.execute_reply.started":"2022-11-28T07:42:19.298394Z","shell.execute_reply":"2022-11-28T07:42:19.303446Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"meta_feature_engineering(meta)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T07:42:19.387151Z","iopub.execute_input":"2022-11-28T07:42:19.388471Z","iopub.status.idle":"2022-11-28T07:42:19.449271Z","shell.execute_reply.started":"2022-11-28T07:42:19.388414Z","shell.execute_reply":"2022-11-28T07:42:19.447856Z"},"trusted":true},"execution_count":161,"outputs":[{"execution_count":161,"output_type":"execute_result","data":{"text/plain":"       album_id                        title   sub_title genre_large  \\\n0           749                     어둠이 무서워요    꼬마버스 타요1          키즈   \n1           750                       우리는 친구    꼬마버스 타요1          키즈   \n2          2131                     타요의 첫 운행    꼬마버스 타요1          키즈   \n3          2625                      길 잃은 타요    꼬마버스 타요1          키즈   \n4          2594                새내기 꼬마 버스의 하루    꼬마버스 타요1          키즈   \n...         ...                          ...         ...         ...   \n42597     39873  로티프렌즈와 색칠놀이! - 그리피 ＆ 사탕 바구니  로티프렌즈 미술놀이          키즈   \n42598     39874       로티프렌즈와 색칠놀이! - 베블리 ＆ 꽃  로티프렌즈 미술놀이          키즈   \n42599      4779                   손가락을 빨게 돼요        4-5세          키즈   \n42600      4779                   손가락을 빨게 돼요        아이맘콕          키즈   \n42601     11629                       손가락 하나  베이비 타요 동요2          키즈   \n\n      genre_mid genre_small country  run_time  onair_date   cast_1 cast_2  \\\n0          TV만화         NaN      한국       660         NaN       타요     로기   \n1          TV만화         NaN      한국       660         NaN       타요     로기   \n2          TV만화         NaN      한국       660         NaN       타요     로기   \n3          TV만화         NaN      한국       660         NaN       타요     로기   \n4          TV만화         NaN      한국       660         NaN       타요     로기   \n...         ...         ...     ...       ...         ...      ...    ...   \n42597      놀이교실         NaN      한국       477         NaN      NaN    NaN   \n42598      놀이교실         NaN      한국       466         NaN      NaN    NaN   \n42599         책         NaN      한국       293         NaN      NaN    NaN   \n42600         책         NaN      한국       293         NaN      NaN    NaN   \n42601      노래율동         NaN      한국        91         NaN  타요와 친구들    NaN   \n\n      cast_3 cast_4 cast_5 cast_6 cast_7  \n0         라니     가니     시투    NaN    NaN  \n1         라니     가니     시투    NaN    NaN  \n2         라니     가니     시투    NaN    NaN  \n3         라니     가니     시투    NaN    NaN  \n4         라니     가니     시투    NaN    NaN  \n...      ...    ...    ...    ...    ...  \n42597    NaN    NaN    NaN    NaN    NaN  \n42598    NaN    NaN    NaN    NaN    NaN  \n42599    NaN    NaN    NaN    NaN    NaN  \n42600    NaN    NaN    NaN    NaN    NaN  \n42601    NaN    NaN    NaN    NaN    NaN  \n\n[42602 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>album_id</th>\n      <th>title</th>\n      <th>sub_title</th>\n      <th>genre_large</th>\n      <th>genre_mid</th>\n      <th>genre_small</th>\n      <th>country</th>\n      <th>run_time</th>\n      <th>onair_date</th>\n      <th>cast_1</th>\n      <th>cast_2</th>\n      <th>cast_3</th>\n      <th>cast_4</th>\n      <th>cast_5</th>\n      <th>cast_6</th>\n      <th>cast_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>749</td>\n      <td>어둠이 무서워요</td>\n      <td>꼬마버스 타요1</td>\n      <td>키즈</td>\n      <td>TV만화</td>\n      <td>NaN</td>\n      <td>한국</td>\n      <td>660</td>\n      <td>NaN</td>\n      <td>타요</td>\n      <td>로기</td>\n      <td>라니</td>\n      <td>가니</td>\n      <td>시투</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>750</td>\n      <td>우리는 친구</td>\n      <td>꼬마버스 타요1</td>\n      <td>키즈</td>\n      <td>TV만화</td>\n      <td>NaN</td>\n      <td>한국</td>\n      <td>660</td>\n      <td>NaN</td>\n      <td>타요</td>\n      <td>로기</td>\n      <td>라니</td>\n      <td>가니</td>\n      <td>시투</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2131</td>\n      <td>타요의 첫 운행</td>\n      <td>꼬마버스 타요1</td>\n      <td>키즈</td>\n      <td>TV만화</td>\n      <td>NaN</td>\n      <td>한국</td>\n      <td>660</td>\n      <td>NaN</td>\n      <td>타요</td>\n      <td>로기</td>\n      <td>라니</td>\n      <td>가니</td>\n      <td>시투</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2625</td>\n      <td>길 잃은 타요</td>\n      <td>꼬마버스 타요1</td>\n      <td>키즈</td>\n      <td>TV만화</td>\n      <td>NaN</td>\n      <td>한국</td>\n      <td>660</td>\n      <td>NaN</td>\n      <td>타요</td>\n      <td>로기</td>\n      <td>라니</td>\n      <td>가니</td>\n      <td>시투</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2594</td>\n      <td>새내기 꼬마 버스의 하루</td>\n      <td>꼬마버스 타요1</td>\n      <td>키즈</td>\n      <td>TV만화</td>\n      <td>NaN</td>\n      <td>한국</td>\n      <td>660</td>\n      <td>NaN</td>\n      <td>타요</td>\n      <td>로기</td>\n      <td>라니</td>\n      <td>가니</td>\n      <td>시투</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>42597</th>\n      <td>39873</td>\n      <td>로티프렌즈와 색칠놀이! - 그리피 ＆ 사탕 바구니</td>\n      <td>로티프렌즈 미술놀이</td>\n      <td>키즈</td>\n      <td>놀이교실</td>\n      <td>NaN</td>\n      <td>한국</td>\n      <td>477</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>42598</th>\n      <td>39874</td>\n      <td>로티프렌즈와 색칠놀이! - 베블리 ＆ 꽃</td>\n      <td>로티프렌즈 미술놀이</td>\n      <td>키즈</td>\n      <td>놀이교실</td>\n      <td>NaN</td>\n      <td>한국</td>\n      <td>466</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>42599</th>\n      <td>4779</td>\n      <td>손가락을 빨게 돼요</td>\n      <td>4-5세</td>\n      <td>키즈</td>\n      <td>책</td>\n      <td>NaN</td>\n      <td>한국</td>\n      <td>293</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>42600</th>\n      <td>4779</td>\n      <td>손가락을 빨게 돼요</td>\n      <td>아이맘콕</td>\n      <td>키즈</td>\n      <td>책</td>\n      <td>NaN</td>\n      <td>한국</td>\n      <td>293</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>42601</th>\n      <td>11629</td>\n      <td>손가락 하나</td>\n      <td>베이비 타요 동요2</td>\n      <td>키즈</td>\n      <td>노래율동</td>\n      <td>NaN</td>\n      <td>한국</td>\n      <td>91</td>\n      <td>NaN</td>\n      <td>타요와 친구들</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>42602 rows × 16 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Profile \n","metadata":{}},{"cell_type":"code","source":"profile = pd.read_csv(\"/kaggle/input/lgground/profile_data.csv\")\n# we use  / sex / age / pr_interest_keyword_cd_1 / ch_interest_keyword_cd_1  as categorical feature\n# age binning ","metadata":{"execution":{"iopub.status.busy":"2022-11-28T07:15:04.819091Z","iopub.execute_input":"2022-11-28T07:15:04.819587Z","iopub.status.idle":"2022-11-28T07:15:04.844330Z","shell.execute_reply.started":"2022-11-28T07:15:04.819549Z","shell.execute_reply":"2022-11-28T07:15:04.842664Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8311 entries, 0 to 8310\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype \n---  ------                    --------------  ----- \n 0   profile_id                8311 non-null   int64 \n 1   sex                       8311 non-null   object\n 2   age                       8311 non-null   int64 \n 3   pr_interest_keyword_cd_1  8311 non-null   object\n 4   pr_interest_keyword_cd_2  6778 non-null   object\n 5   pr_interest_keyword_cd_3  6231 non-null   object\n 6   ch_interest_keyword_cd_1  8311 non-null   object\n 7   ch_interest_keyword_cd_2  6618 non-null   object\n 8   ch_interest_keyword_cd_3  6029 non-null   object\ndtypes: int64(2), object(7)\nmemory usage: 584.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"###### pr_interest_keyword_cd 경우에는 실제플랫폼 특성을 확인 요망 ... 좀 더 고민","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def profile_feature_engineering(profile):\n    #######  sex / age / pr_interest_keyword_cd_1 / ch_interest_keyword_cd_1 - categorical\n    cat_features = ['sex','age','pr_interest_keyword_cd_1','ch_interest_keyword_cd_1']\n    for i in enumerate(cat_features) :\n        col = i[1]\n        profile[col] = profile[col].astype('category')\n        \n    ####### age binning    \n    bins = [0,2,5,7,10,13] \n    group_names = ['영아','유아','초등준비','초등저학년','초등고학년'] #한솔교육 제품군 참조\n    profile['age_bin'] = pd.cut(profile['age'],bins,labels=group_names)\n    profile['age_bin'] = profile['age_bin'].astype('category')    \n    \n    return profile","metadata":{"execution":{"iopub.status.busy":"2022-11-28T07:30:19.396816Z","iopub.execute_input":"2022-11-28T07:30:19.398130Z","iopub.status.idle":"2022-11-28T07:30:19.405532Z","shell.execute_reply.started":"2022-11-28T07:30:19.398079Z","shell.execute_reply":"2022-11-28T07:30:19.404351Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"profile_feature_engineering(profile)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T07:30:30.254248Z","iopub.execute_input":"2022-11-28T07:30:30.254637Z","iopub.status.idle":"2022-11-28T07:30:30.281289Z","shell.execute_reply.started":"2022-11-28T07:30:30.254604Z","shell.execute_reply":"2022-11-28T07:30:30.279749Z"},"trusted":true},"execution_count":151,"outputs":[{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"      profile_id sex age pr_interest_keyword_cd_1 pr_interest_keyword_cd_2  \\\n0              3   F   5                      P02                      P04   \n1              5   M   5                      P07                      P08   \n2              7   F   9                      P05                      P03   \n3             12   M   6                      P03                      P06   \n4             16   F  12                      P03                      P06   \n...          ...  ..  ..                      ...                      ...   \n8306       33022   M   1                      P04                      NaN   \n8307       33023   M   5                      P06                      P03   \n8308       33026   F   8                      P01                      P03   \n8309       33027   F   4                      P04                      P05   \n8310       33032   F   5                      P03                      P05   \n\n     pr_interest_keyword_cd_3 ch_interest_keyword_cd_1  \\\n0                         P07                      K01   \n1                         P06                      K05   \n2                         NaN                      K06   \n3                         P02                      K09   \n4                         P01                      K01   \n...                       ...                      ...   \n8306                      NaN                      K04   \n8307                      P07                      K08   \n8308                      P08                      K05   \n8309                      P06                      K03   \n8310                      P07                      K01   \n\n     ch_interest_keyword_cd_2 ch_interest_keyword_cd_3 age_bin  \n0                         K03                      K04      유아  \n1                         K08                      K09      유아  \n2                         K04                      NaN   초등저학년  \n3                         K07                      K03    초등준비  \n4                         K06                      K04   초등고학년  \n...                       ...                      ...     ...  \n8306                      K08                      NaN      영아  \n8307                      K04                      K05      유아  \n8308                      K09                      K06   초등저학년  \n8309                      K01                      K05      유아  \n8310                      K05                      K09      유아  \n\n[8311 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>profile_id</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>pr_interest_keyword_cd_1</th>\n      <th>pr_interest_keyword_cd_2</th>\n      <th>pr_interest_keyword_cd_3</th>\n      <th>ch_interest_keyword_cd_1</th>\n      <th>ch_interest_keyword_cd_2</th>\n      <th>ch_interest_keyword_cd_3</th>\n      <th>age_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>F</td>\n      <td>5</td>\n      <td>P02</td>\n      <td>P04</td>\n      <td>P07</td>\n      <td>K01</td>\n      <td>K03</td>\n      <td>K04</td>\n      <td>유아</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>M</td>\n      <td>5</td>\n      <td>P07</td>\n      <td>P08</td>\n      <td>P06</td>\n      <td>K05</td>\n      <td>K08</td>\n      <td>K09</td>\n      <td>유아</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>F</td>\n      <td>9</td>\n      <td>P05</td>\n      <td>P03</td>\n      <td>NaN</td>\n      <td>K06</td>\n      <td>K04</td>\n      <td>NaN</td>\n      <td>초등저학년</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12</td>\n      <td>M</td>\n      <td>6</td>\n      <td>P03</td>\n      <td>P06</td>\n      <td>P02</td>\n      <td>K09</td>\n      <td>K07</td>\n      <td>K03</td>\n      <td>초등준비</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>F</td>\n      <td>12</td>\n      <td>P03</td>\n      <td>P06</td>\n      <td>P01</td>\n      <td>K01</td>\n      <td>K06</td>\n      <td>K04</td>\n      <td>초등고학년</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8306</th>\n      <td>33022</td>\n      <td>M</td>\n      <td>1</td>\n      <td>P04</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>K04</td>\n      <td>K08</td>\n      <td>NaN</td>\n      <td>영아</td>\n    </tr>\n    <tr>\n      <th>8307</th>\n      <td>33023</td>\n      <td>M</td>\n      <td>5</td>\n      <td>P06</td>\n      <td>P03</td>\n      <td>P07</td>\n      <td>K08</td>\n      <td>K04</td>\n      <td>K05</td>\n      <td>유아</td>\n    </tr>\n    <tr>\n      <th>8308</th>\n      <td>33026</td>\n      <td>F</td>\n      <td>8</td>\n      <td>P01</td>\n      <td>P03</td>\n      <td>P08</td>\n      <td>K05</td>\n      <td>K09</td>\n      <td>K06</td>\n      <td>초등저학년</td>\n    </tr>\n    <tr>\n      <th>8309</th>\n      <td>33027</td>\n      <td>F</td>\n      <td>4</td>\n      <td>P04</td>\n      <td>P05</td>\n      <td>P06</td>\n      <td>K03</td>\n      <td>K01</td>\n      <td>K05</td>\n      <td>유아</td>\n    </tr>\n    <tr>\n      <th>8310</th>\n      <td>33032</td>\n      <td>F</td>\n      <td>5</td>\n      <td>P03</td>\n      <td>P05</td>\n      <td>P07</td>\n      <td>K01</td>\n      <td>K05</td>\n      <td>K09</td>\n      <td>유아</td>\n    </tr>\n  </tbody>\n</table>\n<p>8311 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"profile.info()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T07:30:39.658719Z","iopub.execute_input":"2022-11-28T07:30:39.659124Z","iopub.status.idle":"2022-11-28T07:30:39.674821Z","shell.execute_reply.started":"2022-11-28T07:30:39.659090Z","shell.execute_reply":"2022-11-28T07:30:39.673813Z"},"trusted":true},"execution_count":152,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8311 entries, 0 to 8310\nData columns (total 10 columns):\n #   Column                    Non-Null Count  Dtype   \n---  ------                    --------------  -----   \n 0   profile_id                8311 non-null   int64   \n 1   sex                       8311 non-null   category\n 2   age                       8311 non-null   category\n 3   pr_interest_keyword_cd_1  8311 non-null   category\n 4   pr_interest_keyword_cd_2  6778 non-null   object  \n 5   pr_interest_keyword_cd_3  6231 non-null   object  \n 6   ch_interest_keyword_cd_1  8311 non-null   category\n 7   ch_interest_keyword_cd_2  6618 non-null   object  \n 8   ch_interest_keyword_cd_3  6029 non-null   object  \n 9   age_bin                   8311 non-null   category\ndtypes: category(5), int64(1), object(4)\nmemory usage: 367.0+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"############ 테스트해보기 (numeric or categorical?)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############ memory reduce + 자동화 ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# day_week feature engineering\n- to split label, train data","metadata":{}},{"cell_type":"code","source":"df_train_week = day_week_feature_engineering(df_train_week)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# label & train split","metadata":{}},{"cell_type":"code","source":"# Label, train data split\ndf_train, label_df = train_label_split(df_train_week)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = 25","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prerpocess","metadata":{}},{"cell_type":"code","source":"personal_train = df_train.drop_duplicates(subset=['profile_id','album_id','ss_id'])\ndf_train = df_train.drop_duplicates(subset=['profile_id','album_id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 라벨 유저 한정1\n# customers = label_df.profileQ_id.unique()\n# 전체 유저 한정\ncustomers = df_train.profile_id.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MP","metadata":{}},{"cell_type":"code","source":"MP_df = df_train.album_id.value_counts().head(50).reset_index()\nMP_df.columns = ['album_id','total_counts']\nMP_df['join_col'] = 1\n\ncustomer_df = df_train_week[['profile_id']].drop_duplicates()\ncustomer_df['join_col'] = 1","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MP_cand = customer_df.merge(MP_df, on='join_col').drop_duplicates(subset=['profile_id','album_id'])[['profile_id','album_id','total_counts']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# general MP\n- 마지막 1주, 2주의 MP를 각 유저마다 넣는다.","metadata":{}},{"cell_type":"code","source":"last_week_list = np.sort(df_train.week.unique())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('중복제거 후 데이터 수:', len(df_train_week))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 마지막 6,5주 각각 MP를 10개 뽑음\nlast_week_ver1 = last_week_list[-1]\nlast_week_ver2 = last_week_list[-2]\n\nMP_latest_ver1_df = df_train.query(f\"week == {last_week_ver1}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MP_df = MP_latest_ver1_df.groupby('album_id')['profile_id'].count().sort_values(ascending=False)\nMP_df = MP_df.reset_index()\nMP_df.columns = ['album_id','counts']\nMP_candidate_df = MP_df[:10].copy()\nMP_candidate_df['join_col'] = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train_week 전체 유저 대상으로 후보군을 뽑을 것임\ncustomer_df = df_train_week[df_train_week['profile_id'].isin(customers)][['profile_id']]\ncustomer_df['join_col'] = 1\npopular_articles_cand_ver1 = customer_df.copy()\npopular_articles_cand_ver1 = popular_articles_cand_ver1.merge(MP_candidate_df, on=\"join_col\")\n\npopular_articles_cand_ver1.drop_duplicates(subset=['profile_id','album_id'],inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MP_latest_ver2_df = df_train.query(f\"week == {last_week_ver2}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MP_df = MP_latest_ver2_df.groupby('album_id')['profile_id'].count().sort_values(ascending=False)\nMP_df = MP_df.reset_index()\nMP_df.columns = ['album_id','general_counts']\nMP_candidate_df = MP_df[:10].copy()\nMP_candidate_df['join_col'] = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_df = df_train_week[df_train_week['profile_id'].isin(customers)][['profile_id']]\ncustomer_df['join_col'] = 1\npopular_articles_cand_ver2 = customer_df.copy()\npopular_articles_cand_ver2 = popular_articles_cand_ver2.merge(MP_candidate_df, on=\"join_col\")\n\npopular_articles_cand_ver2.drop_duplicates(subset=['profile_id','album_id'],inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"popular_articles_cand = pd.concat([popular_articles_cand_ver1, popular_articles_cand_ver2])\npopular_articles_cand = popular_articles_cand.groupby(['profile_id','album_id'])['general_counts'].sum().reset_index()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# personal_MP","metadata":{}},{"cell_type":"code","source":"personal_MP_df = personal_train.groupby(['profile_id','album_id'])[['ss_id']].count().reset_index()\npersonal_MP_df.columns = ['profile_id','album_id','personal_counts']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 서로 다른날 5회 이상 시청한 앨범만\npersonal_MP = personal_MP_df[personal_MP_df['personal_counts'] >= 5]\npersonal_MP = personal_MP.sort_values(by=['profile_id','personal_counts'],ascending=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 상위 5개만 pick\nhead_df_list = []\n# 전체 유저 대상으로 뽑기\nfor user_id in tqdm(customer_df.profile_id.unique()):\n    personal_MP_user_len = len(personal_MP[personal_MP['profile_id']==user_id].head())\n    random_choice_list = personal_MP.album_id.unique()\n    if personal_MP_user_len <5:\n        # 5개 아이템이 없는 경우 랜덤으로 없는 개수만 만큼 choice\n        user_df = personal_MP[personal_MP['profile_id']==user_id]\n        df = pd.DataFrame()\n        random_choices = np.random.choice(random_choice_list, size=(5-personal_MP_user_len))\n        df['profile_id'] = [user_id for _ in range(5-personal_MP_user_len)]\n        df['album_id'] = random_choices\n        df = pd.concat([user_df, df])\n        head_df_list.append(df)\n    else:\n        head_df_list.append(personal_MP[personal_MP['profile_id']==user_id].head())\n        \npersonal_MP_candidate = pd.concat(head_df_list)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MP_user_genre","metadata":{}},{"cell_type":"code","source":"# week, day, album_cnt, rank 컬럼 candidate 붙여야 함\n# df_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_df = pd.read_csv(path+'meta_data.csv')\nmeta_df = meta_df[['album_id','genre_mid','run_time','cast_1','cast_2','cast_3']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_meta = df_train.merge(meta_df, on='album_id')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_genre_df = df_train_meta.groupby(['profile_id','genre_mid']).count()['ss_id'].reset_index()\nuser_genre_df.columns = ['profile_id','genre_mid','genre_cnt']\nuser_genre_df = user_genre_df.groupby(['profile_id','genre_mid']).sum().reset_index().sort_values(by=['profile_id','genre_cnt'],ascending=False)\n\n# 장르 선호도 피처 만들기\n## 100이상 시청한 사람들만 percent\nuser_total_watch_dict = user_genre_df.groupby('profile_id')['genre_cnt'].sum()\\\n                        [user_genre_df.groupby('profile_id')['genre_cnt'].sum()>=100].to_dict()\n# 전체 시청 피처 만들기\nuser_genre_df['user_genre_cnt'] = user_genre_df['profile_id'].apply(lambda x: user_total_watch_dict.get(x, None))\nuser_genre_df['user_genre_percent'] = user_genre_df['genre_cnt']/user_genre_df['user_genre_cnt']\nuser_genre_df.drop(columns=['user_genre_cnt'],inplace=True)\nuser_genre_df.dropna(subset=['user_genre_percent'],axis=0,inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"genre_top_items = {}\ngenre_count = df_train_meta['genre_mid'].value_counts()\nfor genre in genre_count.index:\n    genre_top_items[genre] = list(df_train_meta[df_train_meta['genre_mid']==genre]['album_id'].value_counts().head(10).index)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_list = []\nfor user_id in customer_df.profile_id.unique():\n    user_genres = user_genre_df[user_genre_df['profile_id']== user_id].head(2)['genre_mid']\n    \n    df = pd.DataFrame()\n    if len(user_genres) == 0:\n        \n        df['album_id'] = genre_top_items['노래율동']\n        df['album_id'] = genre_top_items['TV만화']\n        \n    elif len(user_genres) == 1:\n        genre_list_1 = genre_top_items[user_genres.values[0]]\n        genre_list_2 = genre_top_items['노래율동']\n        df['album_id'] = list(dict.fromkeys(np.append(genre_list_1,genre_list_2)))\n        \n    elif len(user_genres) == 2:\n        genre_list_1 = genre_top_items.get(user_genres.values[0],[])\n        genre_list_2 = genre_top_items.get(user_genres.values[1],[])\n        df['album_id'] = list(dict.fromkeys(np.append(genre_list_1,genre_list_2)))\n\n    df['profile_id'] = user_id\n    df_list.append(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"genre_candidate = pd.concat(df_list, ignore_index=True)\ngenre_candidate = genre_candidate[['profile_id','album_id']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ALS MF candidate","metadata":{}},{"cell_type":"code","source":"from ALS_MF import MF\nmodel = MF(df_train_week,label_df)\nals_candidate, item_factors_feature, user_factors_feature = model.mf_train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# apriori candidaate","metadata":{}},{"cell_type":"code","source":"from apriori import apriori_train, apriori_candidate","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules_confidence_item_week = apriori_train(df_train_week, 0.1, 0.8)\napriori_candidate, apriori_feature = apriori_candidate(df_train_week, rules_confidence_item_week)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"apri_list = []\nfor i_list in apriori_candidate.album_id:\n    apri_list.append(str(i_list))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(apri_list).value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# candidate merge","metadata":{}},{"cell_type":"code","source":"popular_articles_cand.album_id.nunique(), personal_MP_candidate.album_id.nunique(), genre_candidate.album_id.nunique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MP_cand.drop(columns=['counts'],inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"candidate_0 = MP_cand\ncandidate_1 = popular_articles_cand[['profile_id','album_id']]\ncandidate_2 = personal_MP_candidate[['profile_id','album_id']]\ncandidate_3 = genre_candidate[['profile_id','album_id']]\ncandidate_4 = als_candidate.copy()\ncandidate_5 = apriori_candidate.copy()\n\ncand = pd.concat([candidate_0, candidate_1, candidate_2, candidate_3, candidate_4, candidate_5])\n# cand = candidate_0.copy()\ncand.drop_duplicates(subset=['profile_id','album_id'],inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"candidate = pd.merge(cand, popular_articles_cand[['album_id','general_counts']].drop_duplicates(), how='left', on='album_id')\n# personal_MP_df 달라짐\ncandidate = pd.merge(candidate,personal_MP_df, how='left', on=['profile_id','album_id'])\n# candidate = pd.merge(candidate, apriori_feature, how=\"left\", on=[\"profile_id\",\"album_id\"])","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('candidate 데이터 수:',len(candidate), 'cand 데이터 수:',len(cand))\nprint('candidate nunique: ', candidate.album_id.nunique())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model preprocess","metadata":{}},{"cell_type":"code","source":"profile_df = pd.read_csv(path+'profile_data.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"candidate_add_features = pd.merge(candidate,profile_df, how='left', on='profile_id')\ncandidate_add_features = pd.merge(candidate_add_features,meta_df.drop_duplicates('album_id'), how='left', on='album_id')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# columns = ['sex','pr_interest_keyword_cd_1','pr_interest_keyword_cd_2','pr_interest_keyword_cd_3','ch_interest_keyword_cd_1','ch_interest_keyword_cd_2','ch_interest_keyword_cd_3',\\\n# 'genre_mid','cast_1','cast_2','cast_3']\n# from sklearn.preprocessing import LabelEncoder\n# for col in columns:\n#     LE = LabelEncoder()\n#     candidate_add_features[col] = LE.fit_transform(candidate_add_features[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"candidate_add_features = candidate.copy()\n# candidate_add_features = candidate_add_features.drop(columns=['personal_counts','pr_interest_keyword_cd_1',\\\n#                                                               'pr_interest_keyword_cd_2','pr_interest_keyword_cd_3'\\\n#                                                               ,'ch_interest_keyword_cd_1','ch_interest_keyword_cd_2'\\\n#                                                               ,'ch_interest_keyword_cd_3',\\\n#                                                                 'genre_mid','cast_1','cast_2','cast_3'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"candidate_add_features = pd.merge(candidate_add_features, item_factors_feature, how=\"left\", on=\"album_id\")\ncandidate_add_features = pd.merge(candidate_add_features, user_factors_feature, how=\"left\", on=\"profile_id\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.merge(candidate_add_features, label_df, how='left', on=['profile_id','album_id'])\ntrain_df['rating'] = train_df['rating'].fillna(0)\n# train_df = train_df.drop(columns=\"personal_counts\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model","metadata":{}},{"cell_type":"code","source":"train_df.rating.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbmrank = LGBMRank(train_df, mode='week', model_params={'n_estimators':5})\nX_train, sample_sumbission = lgbmrank.valid_evaluation()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbmrank = LGBMRank(train_df, mode='week', model_params={'n_estimators':5})\nX_train, sample_sumbission = lgbmrank.valid_evaluation()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cold user MP로 채우기 \nMP_list = MP_cand.album_id.unique()\n\nsample_sumbission_cold = sample_sumbission.copy()\nsample_sumbission_cold['album_id'] = sample_sumbission_cold['album_id']\\\n                                        .apply(lambda x: list(dict.fromkeys(np.append(x, MP_list)))[:n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ndcg_calculator(sample_sumbission_cold, test_answer_week, n)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_list = {}\nfor list_i in sample_sumbission.album_id:\n    set_list[str(list_i)] = 0\nlen(set_list)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"### experiment\n- num_leaves= 20, learning_rate=0.005, n_estimators:5\n- 어느 cand 중요한 지 판단\n- popular_articles_cand :(10,10) , personal_MP_candidate:(5), genre_candidate: max(10,10)\n\n### week\n- week ndcg score : 0.05611031122402796\n- popular_articles_cand week: ndcg 0.028022766659891125 (total unique item: 12)\n- personal_MP_candidate week: ndcg 0.02896244104871668  (total unique item: 4303)\n- genre_candidate week:       ndcg 0.01579135161487282  (total unique item: 157)\n- (popular_articles_cand, personal_MP_candidate) week: ndcg 0.05206722084683086  (total unique item: 4303)\n- (popular_articles_cand, genre_candidate) week: 0.03809584406788012 (total unique item: 161)\n- (personal_MP_candidate, genre_candidate) week: 0.041085241338965385 (total unique item: 4338)\n\n### month\n- month ndcg score : 0.08036130090004782\n- popular_articles_cand month: ndcg 0.05945057771810242 (total unique item: 15)\n- personal_MP_candidate month: ndcg 0.028477345633295483  (total unique item: 2826)\n- genre_candidate       month: ndcg 0.017431233023063257  (total unique item: 150)\n- (popular_articles_cand, personal_MP_candidate) month: ndcg 0.05206722084683086  (total unique item: 2826)\n- (popular_articles_cand, genre_candidate) month: 0.0680887232688415 (total unique item: 155)\n- (personal_MP_candidate, genre_candidate) month: 0.041085241338965385 (total unique item: 2872)","metadata":{}},{"cell_type":"code","source":"def evaluation(\n            X_train:pd.DataFrame(), \n            sumbission:pd.DataFrame(), \n            n:int, \n            MP_cand:pd.DataFrame()\n            )->pd.DataFrame():\n    \n    MP_list = MP_cand.album_id.unique()\n    \n    # each user pred 25 items\n    lgbm_sub_df = X_train.sort_values(by='pred', ascending=False).groupby('profile_id').head(n)\n    lgbm_user_items_dict = lgbm_sub_df.groupby('profile_id')['album_id'].unique().to_dict()\n    sumbission['predicted_list'] = sumbission['profile_id']\\\n                                            .apply(lambda x: lgbm_user_items_dict.get(x, []))\n    \n    # cold start user file MP_list top25\n    sumbission_cold = sumbission.copy()\n    sumbission_cold['predicted_list'] = sumbission_cold['predicted_list']\\\n                                            .apply(lambda x: list(dict.fromkeys(np.append(x, MP_list)))[:n])\n    \n    return sumbission, sumbission_cold","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(path + 'sample_submission.csv')\nsumbission_pred, sumbission_cold = evaluation(X_train, submission, n, MP_cand)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_list = {}\nfor list_i in sumbission_cold.predicted_list:\n    set_list[str(list_i)] = 0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('같은 추천을 받은 유저 수:', 8311 - len(set_list))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sumbission_cold","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 제출 조건 충족 확인\nassert submission.profile_id.nunique() == sumbission_cold.profile_id.nunique()\nfor pred_list in sumbission_cold.predicted_list:\n    assert len(pred_list) == 25","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sumbission_cold","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sumbission_cold.to_csv('lgbm_candidate_submission_ver5_alsvector.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}